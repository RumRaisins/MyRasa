version: "2.0"

language: "zh"

#pipeline:
#- name: LanguageModelTokenizer
## UnsupportedLanguageError: component 'LanguageModelTokenizer' does not support language 'zh'.
##- name: "LanguageModelTokenizer"
#- name: LanguageModelFeaturizer
#  model_name: "bert"
#  # Pre-Trained weights to be loaded
#  model_weights: "bert-base-chinese"
#  # An optional path to a specific directory to download and cache the pre-trained model weights.
#  # The `default` cache_dir is the same as https://huggingface.co/transformers/serialization.html#cache-directory .
#  #cache_dir: "models/"
## classfier and Entity
#- name: DIETClassifier

pipeline:
- name: "JiebaTokenizer"
  dictionary_path: "data/jieba_userdict/jieba_userdict.txt"
- name: "RegexFeaturizer"
- name: "CountVectorsFeaturizer"
  analyzer: "char_wb"
  min_ngram: 1
  max_ngram: 4
- name: "DIETClassifier"


policies:
  - name: MemoizationPolicy
  - name: TEDPolicy
    max_history: 5
    epochs: 200
  - name: RulePolicy